<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="google-site-verification" content="hQv_pITlFxZ6tVh03qHG7esmqo7g-3ak5aHvTHBtmBw" />
    <meta name="author" content="">

    <title>Jiayi Wei Home Page / 魏嘉毅的主页</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>

    <!-- Plugin CSS -->
    <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/creative.min.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top">

    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span> Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">WEI&nbsp;&nbsp;&nbsp;&nbsp;<small>All by effort</small></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="page-scroll" href="#about">About</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#services">Project</a>
                    </li>
		    <!--li>
                        <a class="page-scroll" href="./for_xuxu/index.html">XuXu</a>
                    </li-->
                    <li>
                        <a class="page-scroll" href="#contact">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <header id="about">
        <div class="header-content">
            <div class="header-content-inner">
                <h1 id="homeHeading">Hi! This is Jiayi Wei</h1>
                <hr>
                <p><font color="#FFFFFF"><b>Writing nice code is not just for a better work, but for a more wonderful world.
                	<br><br>I am currently a Software Engineer working on Shopping Search Engine at Google.
                	What attract me the most is to solve real-life tasks with my machine learning and engineering knowledge. 
                	What's more, I'm excited about the technology development and to learn something new everyday!
                	<br><br>If you share the same interesting with me, let's have a <a href="#contact">talk</a>!</b></font></p>
            </div>
        </div>
    </header>
	
	<section id="services">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h1 class="section-heading">My Projects:</h1>
					<hr class="primary">
                </div>
				<div class="space"><p><br></br><br></br></p></div>
            </div>
        </div>
        
        <div class="container">
        	<div class="row">
                <div class="space"></div>


            <div class="row">
					<h2 id="project"><b>Visual Question Rewriting for Increasing Response Rate</b></h2>
					<div class="col-md-5 text-center">
						<img src="img/VQR.jpg" alt="">
						<div class="space"></div>
					<div class="space"><p><br></br></p></div>

					</div>
					<div class="col-md-7"> 
						<p>This is a project I completed as my Master Project. When browsing the image related content online, questions or topics containing more details and emotion have higher possibility to receive attention. Unfortunately, people who are not good at it may suffer. To solve it, I proposed a new NLP task named Visual Language Rewriting (VQR) which reconstructs a bland question into a detailed and emotional style according to its paired image. For the VQR task, the ability on multi-modal understanding is required.</p>
						<p>View more on <a target="_blank" href="https://github.com/jiayi-wei/Visual-Question-Rewrite">Github</a> or <a target="_blank" href="https://arxiv.org/pdf/2106.02257.pdf">paper</a>.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Created a VQR dataset with 4k of bland-emotional sentences and image triples. All data are collected from Houzz.com and then are cleaned with de-emotionalizing and simplifying original sentence.</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Trained a Seq2Seq based model as our baseline with attention mechanism employed on both text sequence and visual feature extracted from encoder and object detector.</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Designed an advanced Transformer based model with the visual information as conditional input. The language generation task is viewed as a sentence completion task as UniLM's work.</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Both the auto and Amazon Turks evaluation proves the advancement of the Transformer+Vis model.</li>
						</ul>
						<div class="space"><p><br></br></p></div>
					</div>
				</div>
			

			<div class="row">
				<h2><b>Virtual Wardrobe – Outfit Recommendation based on Style Match</b></h2>
				<div class="col-md-7">
					<p>This is a project I completed during Google Internship. The goal of this project is to help user to find out great outfit which could be achieved with apparels in their own wardrobe.</p> 
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Recommended style-compatible apparels from the user’s virtual wardrobe to build outfits with user’s chosen apparel.</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Created a dataset of 200M apparel triples for apparel style compatibility model training, developed a neural network with triplet loss in TensorFlow, and achieved 0.94 AUC score on the test dataset with the best performance model.</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Designed the pipeline in C++ to utilize the trained model to select out style-compatible apparel in wardrobe which can achieve pretty outfits with user’s chosen apparel, and to retrieve visual examples for all potential outfits in the style corpus of 100M images</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Built multi demos for the whole project with multithreading on compatibility selection and low latency image retrieval</li>
						</ul>
				</div>
				<div class="col-md-5 text-center">
					<img src="img/Virtual_Wardrobe.jpg" alt="">
					<div class="space"><br></br></div>
					<div class="space"><p><br></br></p></div>

				</div>
			</div>


        
             <div class="row">
					<h2 id="project"><b>Data Augmentation for Rare Traffic Signs to Boost the Detection Performance</b></h2>
					<div class="col-md-5 text-center">
						<img src="img/stylize.jpg" alt="">
						<div class="space"></div>
					<div class="space"><p><br></br></p></div>

					</div>
					<div class="col-md-7"> 
						<p>This project is part of my Sensetime internship. When training the traffic sign detection model for self-driving vehicles, because of the hardness to create a dataset with all categories balanced, I research to generate synthesized images fo rare categories. Here, we initialized with the application of style transformation on traffic object generation.</p>
            			<p>Because of the policy, no detail or code can be shared publicly.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Initiated research on style transfer to generate rare traffic signs in real traffic scenes, providing more balanced dataset in the following task of traffic sign detection</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Analyzed distribution of traffic signs from 6 categories in 500k images of real traffic scenes, created synthesized images by replacing original traffic signs with rare ones and achieved balance in each category</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Implemented WCT (whitening and coloring transform) and local smoothing algorithm with Pytorch to transfer style from context to traffic sign objects in the synthesized images</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Achieved 94% recall rate in traffic sign detection using the augmented balanced images (35% using original imbalanced dataset and 98% using real balanced dataset under the same 0.1 FPPI)</li>
						</ul>
						<div class="space"><p><br></br></p></div>
					</div>
				</div>
			

			<div class="row">
				<h2><b>NVIDIA AICity Challenge 2019 (CVPRW 2019)</b></h2>
				<div class="col-md-7">
					<p>In this <a target="_blank" href="https://www.aicitychallenge.org/">challenge</a>, I collaborated with students and professors from three different universities. Our algorithms rank 8th, 13th, and 3rd on three tracks respectively among dozens of teams from academia and industry. During the competition, I held weekly meetings, covered the work on track-3 and contributed to the other two tracks.</p> 
					<p>View more on <a target="_blank" href="https://github.com/NVIDIAAICITYCHALLENGE/2019AICITY_Code_From_Top_Teams">Github</a> or 
						<a target="_blank" href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Chang_AI_City_Challenge_2019_--_City-Scale_Video_Analytics_for_Smart_CVPRW_2019_paper.pdf">paper</a>.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Collaborated with professors and students from three universities; held and participated in weekly meetings; independently accomplished the track-3 task and contributed to track-1 and track-2</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Polished the framework I proposed in last year's Challenge for detection and tracking</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Trained a FPN-R-FCN vehicle detection model on more vehicle data and improve the classification model</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Replaced the simple IoU strategy with DaSiamRPN single object tracking algorithms to obtain more accurate timestamps during backtracking in origin video</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Achieved a competitive result of 0.7027 F1-score and 7.4679 RMSE on a much harder dataset compared with last year's challenge</li>
						</ul>
						<div class="space"><p><br></br></p></div>
				</div>
				<div class="col-md-5 text-center">
					<img src="img/nvidia-2.jpg" alt="">
					<div class="space"><br></br></div>
					<div class="space"><p><br></br></p></div>

				</div>
				<div class="space"><p><br></br></p></div>
			</div>
  


			<div class="row">
					<h2><b>Advanced Driving Assistance System (ADAS)</b></h2>
					<div class="col-md-5 text-center">
						<img src="img/adas_.jpg" alt="">
						<div class="space"></div>
					</div>
					<div class="col-md-7">
						<p>This is a project during the internship at Sensetime. Our ADAS system is used in Honda self-driving. My job is to improved the performance of detection model on traffic objects, including traffic light (four status), traffic sign (20 categories) and PVB (pedestrain, vehicle, bike). Besides, due to the limited computation resource, I fused all model together by using shared convolution layers while maintaining the perfect performance.</p>
						<p>This project cannot be put on Git cause of the policy.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Innovated a multi-task architecture in Caffe to accomplish three traffic object detection tasks simultaneously, namely PVB (Pedestrian, Vehicle and Bike) detection, traffic light detection and traffic sign detection</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Shared backbone across three detectors consisted of RPN and Fast R-CNN, which was updated by normalized gradients coming from different detectors</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Exploited mimic learning to refine detectors towards the performance of individually trained networks</li>
              				<li><i class="fa fa-caret-right pr-10 text-colered"></i>Met Honda’s requirements with significantly increased training and inference speed as well as reduced GPU storage</li>
						</ul>
						<div class="space"><p><br></br></p></div>
					</div>
				</div>
				<div class="space"></div>
			</div>
			  

			<div class="row">
				<h2><b>Understanding Vehicle Density in Traffic Surveillance</b></h2>
				<div class="col-md-7">
					<p>When talking about understanding the traffic, the number of vehicles on road is a key to describe the congestion degree. While it is hard for detection models to predict in hard cases (like traffic jams or bad weather). Therefore, borrowing the ability of crowd density estimation methods to work in extreme congestion, I designed an FCN, whose backbone is Inception-v3, to predict the density map. To obtain the accurate estimation, during training I implemented two losses on density map and bias respectively. The bias means the difference between the ground truth of the total number and the number summed on the predicted density map. Finally, the model outperforms the detection based method and runs in real-time.</p> 
					<p>View more on <a target="_blank" href="">Github</a>.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Used a density prediction model with better robustness for traffic jam and low-quality video to obtain the total number of vehicles in real-time</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Designed an FCN with inception-v3 as the backbone to predict density map</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Trained the model with two losses to restrain on density map and total number respectively</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Achieved 94.2% accuracy with speed of 20fps and outperformed the detection-based model</li>
						</ul>
				</div>
				<div class="col-md-5 text-center">
					<img src="img/density_.jpg" alt="">
					<div class="space"></div>
					<div class="space"><p><br></br><br></br></p></div>
				</div>
			</div>
      

				<div class="row">
					<h2><b>Unsupervised Anomaly Detection for Traffic Surveillance (CVPRW 2018)</b></h2>
					<div class="col-md-5 text-center">
						<img src="img/nvidia.png" alt="">
						<div class="space"></div>
					</div>
					<div class="col-md-7">
						<p>This work is for <a target="_blank" href="https://www.aicitychallenge.org/2018-ai-city-challenge/">NVIDIA AI CITY CHALLENGE 2018 track-2</a>, traffic anomaly detection in surveillance video. We figure out the nature among all broken vehicles, that is whenever an anomaly happens, it leads to at least one stopped vehicle, which becomes part of the video background. According to this finding, we designed a framework and our algorithm ranks the <b>2nd</b> in the final competition.</p>
						<p>View more on <a target="_blank" href="https://github.com/NVIDIAAICITYCHALLENGE/2018AICITY_MCPRL">Github</a>.</p>
						<p>Also, you can find the demo video <a target="_blank" href="https://youtu.be/WTD2S94ZUrc">here</a>, and paper is <a target="_blank" href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w3/Wei_Unsupervised_Anomaly_Detection_CVPR_2018_paper.pdf">here</a>.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Designed a novel unsupervised system to detect abnormal vehicles in traffic surveillance videos that could adapt to various scenes without special treatment</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Utilized MOG2 to capture the background frames and implement Faster-RCNN to detect vehicles in background frames, as the abnormal vehicles stay in the video background for a long time; trained a VGG as the classifier to eliminate false detected bounding boxes</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Trained a ReID model, whose backbone is ResNet, with triplet loss to complete the similarity comparison when meeting camera-movement or vehicles waiting for the traffic light</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Designed a decision model to determine whether a detected vehicle is belonged to anomaly according to the bounding boxes obtained above</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Achieved 0.81 F1-score and 10.2 RMSE in traffic anomaly detection dataset on NVIDIA AI CITY Challenge</li>
						</ul>
						<div class="space"><p><br></br></p></div>
					</div>
				</div>
			

			<div class="row">
				<h2><b>License Plates Recognition Based on Segmentation and Multi-Label Classification</b></h2>
				<div class="col-md-7">
					<p>As we all know, almost all existing license plate recognition algorithm can only be utilized in homogeneous scenes. Therefore, I built a license plate recognition system to recognize the Chinese license plate from multi-oriented images which could handle all kinds of scenes in real-time with great robustness. My system can work in real-time and real-life without any specious modification.</p> 
					<p>View more on <a target="_blank" href="">Github</a>.</p>
					<p><a href="#contact">Contact me</a> if want to view more or get my data.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Built a license plate recognition system to detect and recognize the multi-oriented Chinese license plate in kinds of scenes in real-time with great robustness</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Trained a segmentation model to perform pixel-wise classification and obtain the pure license plate area on wild vehicle images, to avoid the inference of background caused by using detection to locate license plate</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Obtained the quadrilateral envelope according to the context hull of the license plate area, and then transform the quadrilateral to rectangle through perspective transformation.</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Designed a CNN with CTC loss to recognize license plate characters end-to-end on rectangular license plate images; trained the classification model on 100k simulated images and fine-tuned on real data due to the lack of annotation</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Achieved 98.1% recognition accuracy from vehicle image to vehicle ID with speed of 50fps</li>
						</ul>
				</div>
				<div class="col-md-5 text-center">
					<img src="img/lp.jpg" alt="">
					<div class="space"><br></br></div>
				</div>
			</div>

			<div class="row">
                <div class="space"></div>
				<div class="row">
					<h2 id="project"><b>Denoising for Cosmic Microwave Background(CMB) Signal with Auto-Encoders.</b></h2>
					<div class="col-md-5 text-center">
						<img src="img/block_4.png" alt="">
						<div class="space"></div>
					</div>
					<div class="col-md-7">
						<p>In this project, my target is to remove tough noise on the data, which is called 'all'. Using the approach of Res-Connection, the signal of noise 
						is obtained from the first autoencoder whose input is the 'all' signal. Sequentially, the difference between the 'all' signal and the 'noise' signal is the input of the next autoencoder.
						A fantastic result has been acquired from the stack of autoencoders.</p>
						<p>View more on <a target="_blank" href="https://github.com/jiayi-wei/Denoising-for-cosmic-microwave-background-CMB-signal">Github</a>.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Designed an Auto-Encoder Network using Residual Connection and Dense Connection which could efficiently reduce the background noise</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Trained two models with same architecture with MSE and MAE loss to learn the noise from original images and to learn CMB signal from the noise free images respectively; connected the two model together using residual connection</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Achieved around 450 MSE and 8 MAE on the evaluation dataset and a decent PSD compared with traditional methods</li>
						</ul>
						<div class="space"><p><br></br></p></div>
					</div>
				</div>
				<div class="space"></div>
			</div>
			
			<div class="row">
				<h2><b>Traffic Signs Detection </b></h2>
				<div class="col-md-7">
					<p>This is a project about detecting traffic signs on the highway. Considering the accuracy and speed, I chose the Faster-RCNN to realize the target.</p> 
					<p>View more on <a target="_blank" href="https://github.com/jiayi-wei/road-sign-detection">Github</a>.</p>
					<a href="#contact">Contact me</a> if want to view more or get my data.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Designed a traffic sign detection system with high accuracy and fast speed</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Annotated 10K+ bounding boxes on 5k+ images captured in various scenes</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Trained Faster-RCNN detection model with 80% labeled data and achieved 97.4% accuracy on the test dataset</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i>Deployed the traffic sign detection system on Windows using QT and hosted the detection model on Linux server</li>
						</ul>
				</div>
				<div class="col-md-5 text-center">
					<img src="img/traffic_sign.jpg" alt="">
					<div class="space"></div>
					<div class="space"><br></br></div>
				</div>
			</div>
			
            <div class="row">
                <div class="space"></div>
				<div class="row">
					<h2 id="project"><b>Lane detection for moving vehicle</b></h2>
					<div class="col-md-5 text-center">
						<img src="img/lane_detection_.jpg" alt="">
						<div class="space"></div>
					</div>
					<div class="col-md-7">
						<p>This is a project I completed during my internship at Samsung China. Because of the mobile is where the program will be used, the runtime and size are equally important. The main idea is to find the line which could be lanes and then consider the change of weight on the location of lanes. Finally, we could figure out the lane or whether the car is changing lanes.</p>
						<p>View more on <a target="_blank" href="https://github.com/jiayi-wei/lane_detection">Github</a>.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i> Design an algorithm for detecting lane through in-vehicle camera in real-time with high accuracy</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i> Implement the algorithm designed by me using C++</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i> Optimize algorithm performance and reduce detection time by more efficient data structure and more elegant logic</li>
						</ul>
						<div class="space"><p><br></br></p></div>
					</div>
				</div>
				<div class="space"></div>
			</div>
			
			<div class="row">
				<h2><b>Video Face Recognition based on Deep Learning</b></h2>
				<div class="col-md-7">
					<p>I begin to touch deep learning with completing this project. As the project going on, I become familiar with the details of deep learning. I spend plenty of time on environment building and debugging actually. It is a big motivation to witness my face recognition model running. 
					<br></br><a href="#contact">Contact me</a> if want to view more. The project is too large to be Gited because of the MFC stuff.</p>
						<ul class="list-unstyled">
							<li><i class="fa fa-caret-right pr-10 text-colored"></i> Completed a demo that can show the identified face appearing in the demo video</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i> Designed a convoluted neural network for face recognition</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i> Trained CNN and adjusted parameters on the Caffe, with CASIA Webface database</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i> Got a further understanding of the implications sorted layers of CNN</li>
							<li><i class="fa fa-caret-right pr-10 text-colored"></i> Achieved 96% accuracy on face recognition and the demo performance well</li>
						</ul>
				</div>
				<div class="col-md-5 text-center">
					<img src="img/face_recog.png" alt="">
					<div class="space"></div>
					<div class="space"><p><br></br><br></br></p></div>
				</div>
			</div>

			<div class="row">
				<h2><b>Handwritten Fuzzy Numeric Characters Recognition</b></h2>
				<div class="col-md-5 text-center">
					<img src="img/number.png" alt="">
					<div class="space"></div>
				</div>
				<div class="col-md-7">
					<p>A simple but important project for me, which triggers me to explore in deep learning and the general machine learning area. I come out with
					 a way to classify the number in pictures, dividing every picture into parts, each of which is used to fit a Guassian distribution.
					Obviously, the EM mothed meets my needs well.</p>
					<p>View more on <a target="_blank" href="https://github.com/jiayi-wei/Handwritten-Fuzzy-Number">Github</a>.</p>
					<ul class="list-unstyled">
						<li><i class="fa fa-caret-right pr-10 text-colored"></i> Build a model that can recognize the fuzzy number in pictures</li>
						<li><i class="fa fa-caret-right pr-10 text-colored"></i> Selected the EM algorithm to complete the recognition work considering the features of numeric characters</li>
						<li><i class="fa fa-caret-right pr-10 text-colored"></i> Completed the designed content using C++</li>
						<li><i class="fa fa-caret-right pr-10 text-colored"></i> Achieved 93% average accuracy in the different character images</li>
					
					</ul>
				</div>
			</div>
				<div class="space"></div>
		</div>
        </div>
    </section>

    <section id="contact" class="bg-dark">
		<div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 text-center">
                    <h1 class="section-heading">Let's Get In Touch!</h1>
                    <hr class="primary">
                    <p>Here is my <a target="_blank" href="https://drive.google.com/file/d/17aUUHORMEW1Y82-M8y9jmb4ZVXSEWzBt/view?usp=sharing">resume</a>. Contact me, if you are insterested.</p>
                </div>
				<div class="col-lg-8 col-lg-offset-2 text-left">
					<p><i class="fa fa-map-marker pr-10"></i>  Cupertino, California, USA, 95014</p>
					<p><i class="fa fa-phone pr-10"></i>  +1 831-400-7538</p>
					<p><i class="fa fa-envelope-o pr-10"></i>  weijiayi1217@gmail.com<br></br></p>
				</div>
                <div class="col-lg-2 col-lg-offset-2 text-center">
                    <a target= "_blank" href="https://scholar.google.com/citations?user=_qNBlA4AAAAJ&hl=en&oi=ao"><i class="fa fa-google-plus fa-3x sr-contact"></i></a>
                </div>
                <div class="col-lg-2 text-center">
                    <a target= "_blank" href="https://github.com/jiayi-wei"><i class="fa fa-github fa-3x sr-contact"></i></a>
                </div>
				<div class="col-lg-2 text-center">
                    <a target= "_blank" href="https://www.linkedin.com/in/wei-jiayi-852a35132/"><i class="fa fa-linkedin fa-3x sr-contact"></i></a>
                </div>
				<div class="col-lg-2 text-center">
                    <a target= "_blank" href="http://weibo.com/2259949191/profile?rightmod=1&wvr=6&mod=personinfo&is_all=1"><i class="fa fa-weibo fa-3x sr-contact"></i></a>
                </div>
            </div>
        </div>
    </section>
	
	<div class="container">
		<div class="row">
			<p class="text-center">Copyright © 2021 by Jiayi Wei.</p>
		</div>
	</div>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="vendor/scrollreveal/scrollreveal.min.js"></script>
    <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/creative.min.js"></script>

</body>

</html>
